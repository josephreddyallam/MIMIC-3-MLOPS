# MIMIC-3-MLOPS
Cloud based Machine Learning model for mortality prediction 


This is my first end-to-end MLOps project focused on building a mortality prediction model for hospitalized patients using the publicly available MIMIC-3 demo dataset.

The goal is to apply real-world data engineering and machine learning practices in a cloud environment.

ğŸ§± Architecture

The project follows the Medallion Architecture (also known as the Bronze-Silver-Gold architecture):
	â€¢	Bronze Layer: Raw data ingestion from 26 MIMIC-3 CSV files.
	â€¢	Silver Layer: Cleaned, joined, and structured data with integrity checks.
	â€¢	Gold Layer: Feature-enriched, model-ready data used for training and inference.

This layered approach ensures modularity, data quality, and reproducibility.


The ML workflow includes:
	1.	Data Preprocessing:
	â€¢	Missing value handling
	â€¢	Feature encoding (one-hot, label encoding)
	â€¢	Outlier treatment
	â€¢	Scaling/skew correction
	2.	Feature Engineering:
	â€¢	Clinical variable aggregation (vitals, labs, etc.)
	â€¢	Length of stay and ED duration
	â€¢	Diagnosis frequency encoding
	â€¢	Comorbidity flags (e.g., Diabetes, Hypertension)
	3.	Model Training:
	â€¢	Logistic Regression and XGBoost with Optuna hyperparameter tuning
	â€¢	Model evaluation with classification metrics and ROC curve
	4.	Inference Pipeline:
	â€¢	Modular pipeline to load model and expected features from Azure Blob Storage
	â€¢	Preprocessing and real-time prediction using the trained model

 â˜ï¸ Cloud Integration
	â€¢	Platform: Azure Databricks (for scalable Spark-based processing)
	â€¢	Storage: Azure Blob Storage (to store models and data)


 Technologies Used

 Python / Pandas / PySpark / XGBoost / Sklearn / Optuna 
 Azure Databricks / Azure Blob Storage / Delta Lake

## ğŸ“ Repository Structure
('''project_mimic/
â””â”€â”€ mlops/
â”œâ”€â”€ cicd/                         # (Planned) CI/CD scripts (not implemented yet)
â”œâ”€â”€ mortality_app/               # Frontend app (currently under development)
â”œâ”€â”€ scripts/                     # Shared utility functions
â”‚   â”œâ”€â”€ init.py
â”‚   â”œâ”€â”€ azure_blob_utils.py
â”‚   â”œâ”€â”€ feature_utils.py
â”‚   â””â”€â”€ model_utils.py
â”œâ”€â”€ src/                         # Source code for training, preprocessing, inference
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ run.py
â”‚   â”‚   â”œâ”€â”€ Setup.py
â”‚   â”‚   â”œâ”€â”€ save_models.py
â”‚   â”‚   â”œâ”€â”€ model_utils.py
â”‚   â”‚   â”œâ”€â”€ model_train.py
â”‚   â”‚   â”œâ”€â”€ load_latest_model.py
â”‚   â”‚   â””â”€â”€ list_models_in_container.py
â”‚   â”œâ”€â”€ pre_processing/
â”‚   â”‚   â”œâ”€â”€ synthetic_data_generation.py
â”‚   â”‚   â”œâ”€â”€ Storage_connections.py
â”‚   â”‚   â””â”€â”€ preprocessing.py
â”‚   â””â”€â”€ inference/
â”‚       â”œâ”€â”€ init.py
â”‚       â”œâ”€â”€ inference_run.py
â”‚       â”œâ”€â”€ inference_pipeline.py
â”‚       â””â”€â”€ prediction_accuracy.py''')



if you using this code pass your  accesskey and blob account names in src/pre_processing/Storage_connections.py
