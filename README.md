# MIMIC-3-MLOPS: Cloud-Based Mortality Prediction

This project is my first end-to-end MLOps solution focused on predicting **hospital mortality** using the publicly available **MIMIC-III demo dataset**. It is built entirely in a cloud environment using **Azure Databricks** and follows modern data engineering and ML best practices.

---

##  Project Objective

Develop a scalable, modular, and production-ready machine learning pipeline to predict mortality risk in ICU patients using real clinical data.

---

##  Architecture: Medallion Pattern

The project is structured using the **Medallion Architecture**:

-  Bronze Layer : Raw ingestion of all 26 MIMIC-III CSV files.
-  Silver Layer : Cleaned, validated, and joined datasets.
-  Gold Layer   : Feature-enriched, model-ready data used for training and inference.

This layered approach ensures:
- Data quality
- Reproducibility
- Maintainability

---

##  Machine Learning Workflow

### 1. Data Preprocessing
- Missing value handling
- One-hot and label encoding
- Outlier capping
- Scaling and skew correction

### 2. Feature Engineering
- Aggregation of vitals and labs
- Length of stay and ED duration features
- Frequency encoding of diagnosis codes
- Comorbidity flags (e.g., Diabetes, Hypertension)

### 3. Model Training
- Algorithms: **Logistic Regression** and **XGBoost**
- Hyperparameter tuning via **Optuna**
- Evaluation metrics: Accuracy, AUC-ROC, Classification Report

### 4. Inference Pipeline
- Load trained model and expected features from **Azure Blob Storage**
- Apply preprocessing to new patient data
- Generate real-time mortality predictions

---

## â˜ï¸ Cloud Integration

- **Platform**: Azure Databricks (PySpark and Python)
- **Storage**: Azure Blob Storage
- **Data Format**: Delta Lake

---

## Technologies Used

- **Languages**: Python, PySpark
- **Libraries**: pandas, scikit-learn, XGBoost, Optuna
- **Cloud Tools**: Azure Blob Storage, Azure Databricks, Delta Lake

---

## ğŸ“ Repository Structure
<pre>
<code>
project_mimic/
â””â”€â”€ mlops/
    â”œâ”€â”€ cicd/                       # (Planned) CI/CD scripts
    â”œâ”€â”€ mortality_app/              # Streamlit-based frontend (under development)
    â”œâ”€â”€ scripts/                    # Shared utility functions
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ azure_blob_utils.py
    â”‚   â”œâ”€â”€ feature_utils.py
    â”‚   â””â”€â”€ model_utils.py
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ training/
    â”‚   â”‚   â”œâ”€â”€ run.py
    â”‚   â”‚   â”œâ”€â”€ setup.py
    â”‚   â”‚   â”œâ”€â”€ save_models.py
    â”‚   â”‚   â”œâ”€â”€ model_utils.py
    â”‚   â”‚   â”œâ”€â”€ model_train.py
    â”‚   â”‚   â”œâ”€â”€ load_latest_model.py
    â”‚   â”‚   â””â”€â”€ list_models_in_container.py
    â”‚   â”œâ”€â”€ pre_processing/
    â”‚   â”‚   â”œâ”€â”€ synthetic_data_generation.py
    â”‚   â”‚   â”œâ”€â”€ Storage_connections.py
    â”‚   â”‚   â””â”€â”€ preprocessing.py
    â”‚   â””â”€â”€ inference/
    â”‚       â”œâ”€â”€ __init__.py
    â”‚       â”œâ”€â”€ inference_run.py
    â”‚       â”œâ”€â”€ inference_pipeline.py
    â”‚       â””â”€â”€ prediction_accuracy.py
</code>
</pre>

Provide:
- `AZURE_STORAGE_ACCOUNT_NAME`
- `AZURE_STORAGE_ACCESS_KEY`

---

##  Future Work

- Model inference and UI via **Streamlit** (WIP)
- Implement CI/CD using GitHub Actions
- Package the entire pipeline with Docker & deployment options

---

## References

- [MIMIC-III Dataset](https://physionet.org/content/mimiciii/1.4/)
- [Azure Databricks](https://azure.microsoft.com/en-us/products/databricks/)

---

##  Author

**Joseph Reddy**  
_Data Engineer Intern | Azure & MLOps Enthusiast_  
ğŸ”— [GitHub](https://github.com/josephreddyallam)

---
